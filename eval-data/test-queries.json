[
  {
    "input": "Explain about the architecture in details",
    "expected": "DPIP (Digital Payment Intelligence Platform) is designed on a hybrid central-and-edge architecture. This model aims to provide a single, authoritative source of nationwide fraud intelligence while enabling near-instantaneous screening performance within each participating bank's own infrastructure.\n\nThe two primary parts of this architecture are:\n\nThe Central DPIP Service:\n- This is the core hub managed by the RBI.\n- Acts as the definitive master registry for all known fraudulent identifiers.\n- Provides a secure interface to receive and process fraud reports from all participating institutions.\n- Makes the master fraud list available for Edge Services to synchronize with.\n- Provides a dedicated interface to manage the dispute resolution process for contested fraud entries.\n\nThe Edge Cache Service (Bank Edge Service):\n- A lightweight service deployed by a participating bank within its own technology stack.\n- Maintains a local copy of the fraudulent identifiers from the Central DPIP Service and periodically syncs to keep its data current.\n- During an onboarding or transaction flow, a bank's systems interact exclusively with its local Edge Cache, allowing extremely low-latency fraud checks without requiring a real-time call to the central service.\n\nCore Components of the Bank Edge Service:\n- Replication Service: Background process that syncs with the Central DPIP Service to download the latest fraudulent identifiers and updates the local data store (Redis).\n- Screening Service: API endpoint called by a bank's systems to perform real-time fraud checks. Uses a Bloom Filter for rapid pre-checks.\n- Bloom Filter: Probabilistic data structure used to quickly rule out identifiers that are not in the fraud list. If a match is possible, a definitive lookup is done in Redis.\n\nData Flow & Interaction Model:\n\n1. Real-time Transaction Screening Flow:\n- Bank app sends transaction identifiers (e.g., Account number, VPA, mobile number, PAN) to the local Screening Service.\n- Bloom Filter is queried first.\n- If negative → \"Clear\" response is returned.\n- If positive → Redis Cache is queried for definitive match. Returns \"Found\" or \"Not Found\".\n\n2. Data Synchronization Flow:\n- Replication Service periodically contacts Central DPIP Service.\n- Fetches new or updated identifiers.\n- Updates local Redis Cache and rebuilds the Bloom Filter.\n\n3. Fraud Reporting Flow:\n- Bank confirms a fraudulent entity.\n- Sends a secure API request with the identifier to the Central DPIP Service.\n- Central DPIP validates and adds it to the master Fraud Registry.\n- New data is distributed to other banks in their next sync cycle.\n\nKey Architectural Principles:\n- Ultra-Low Latency & High Throughput: <50ms lookups, scales to 25B+ transactions/month, in-memory caching, near real-time updates.\n- Reliability: Active-active configurations, automated failover, disaster recovery, rate limiting.\n- Extensibility: Modular design to support new identifier types and detection logic.\n- Security: End-to-end encryption (mTLS 1.2+), RBAC, hashing, privacy-preserving design, immutable audit trails.\n\nDeployment Options for Edge Service:\n\n1. Complete Edge Deployment (Recommended):\n- Includes Screening Service, Redis Cache (full data), Bloom Filter.\n- All lookups done locally. Ultra-low latency. Resilient to internet issues.\n\n2. Bloom-Only Edge Deployment:\n- Includes Screening Service and Bloom Filter only.\n- If Bloom indicates a match, real-time API call is made to Central DPIP.\n- Lower infra cost, but depends on network and has higher latency for matches."
  },
  {
    "input": "What is the latency of the Bloom filter. How much TPS can bloom filter support",
    "expected": "The Bloom filter, as a component of the DPIP Edge Service, is designed for extremely low latency to enable rapid pre-checks in the fraud screening process.\n\nHere's a summary of its latency and capacity:\n\nLatency of the Bloom Filter:\n\nWithin the DPIP architecture, the Bloom filter (Layer 1 of the Screening Service) is the fastest component. It has a real-world latency of approximately 1.0 – 1.5 milliseconds (ms).\n\nThis ultra-low latency is crucial because the Bloom filter handles nearly all the initial lookup load (99.89% of traffic in a balanced system) and quickly determines if an identifier is definitively not associated with fraud, allowing the majority of legitimate transactions to pass through instantly.\n\nTPS (Transactions Per Second) / QPS (Queries Per Second) Support:\n\nThe Bloom filter is highly efficient and scalable. In the context of DPIP's design, which targets a peak load of 100,000 queries per second (QPS), the Bloom filter layer is designed to handle 100% of this traffic.\n\nThis means it can support 100,000 QPS directly, effectively serving as the primary filter for all incoming transaction screening requests.\n\nThe documents mention a capacity of ~3,330 lookups/sec per core or ~106,000 lookups/sec per 32 vCPU server for the Bloom filter, demonstrating its high throughput capability.\n\nIn essence, the Bloom filter's performance is characterized by its near-instantaneous response time and its ability to handle a massive volume of queries, making it ideal for the first, rapid check in a high-throughput system like DPIP."
  },
  {
  "input": "DPIP will support up to how much TPS to ingest data",
  "expected": "The DPIP system is designed to support a specific throughput for data ingestion into its central registry.\n\nThe number of ingestions (new fraud reports or updates) to the Smart Registry that DPIP is designed to handle is 10 Ingestions Per Second (IPS). This is one of the key requirements for the infrastructure sizing of the system."
  },
  {
    "input": "What are the methods to integrate with DPIP",
    "expected": "There are two distinct methods for integrating with the Digital Payment Intelligence Platform (DPIP):\n\nSDK Integration: This is the strongly recommended method as it simplifies development and ensures adherence to best practices. DPIP provides specific SDKs for various functionalities:\n\nIngestion SDK: For pushing identifiers and entity data to the central system. It supports JSON, Excel, and XML file formats and offers methods like registerReportFromJson to convert data for submission.\n\nScreening SDK: For real-time decisioning on transactions and critical workflows.\n\nDispute SDK: To facilitate raising and viewing fraud disputes.\n\nTesting SDK: For interacting with sandbox environments and performing health checks, including end-to-end flows like ingestion, screening, and dispute.\n\nDirect API Integration: This method offers maximum flexibility for teams that need to build their own integration logic or are using a programming language for which an SDK is not yet available. It involves making direct HTTP requests to the DPIP Edge Service's local API endpoint.\n\nWhen using this method, the integrating entity is responsible for:\n\nStandardization and validation of data.\n\nConverting valid data to uppercase.\n\nHashing the identifier.\n\nApplying JWE (JSON Web Encryption) and JSE (JSON Serialization and Encryption) for encryption."
  }
]
